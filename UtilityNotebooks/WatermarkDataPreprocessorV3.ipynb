{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f158dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "from sematch.semantic.similarity import WordNetSimilarity\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e625ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.corpus.brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b917384a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opponents',\n",
       " 'generally',\n",
       " 'argued',\n",
       " 'that',\n",
       " 'the',\n",
       " 'ballot',\n",
       " \"couldn't\",\n",
       " 'give',\n",
       " 'enough',\n",
       " 'information',\n",
       " 'about',\n",
       " 'tax',\n",
       " 'proposals',\n",
       " 'for',\n",
       " 'the',\n",
       " 'voters',\n",
       " 'to',\n",
       " 'make',\n",
       " 'an',\n",
       " 'intelligent',\n",
       " 'choice',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example sentence.\n",
    "sentences[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e0ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercases all words currently for simplicity.\n",
    "def watermark_sentence(orig_sentence):\n",
    "    # Can add\n",
    "    sentence = [word.lower() for word in orig_sentence.copy()]\n",
    "    \n",
    "    # Get the best synonym starting with the word at the end of the sentence.\n",
    "    result = get_best_synonym(sentence)\n",
    "    \n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    best_synonym, best_synonym_index = result\n",
    "    \n",
    "    # Replace the target word with the synonym.\n",
    "    sentence[best_synonym_index] = best_synonym\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a34c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_synonyms(word):\n",
    "    word = word.lower()\n",
    "    synonyms = []\n",
    "    scores = []\n",
    "    for ss in wn.synsets(word):\n",
    "        synonyms.extend([lemma.lower() for lemma in ss.lemma_names()])\n",
    "        for sim in ss.similar_tos():\n",
    "            synonyms_batch = sim.lemma_names()\n",
    "            synonyms.extend(synonyms_batch)\n",
    "    synonyms = set(synonyms)\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    synonyms = [synonym.replace('_',' ') for synonym in synonyms]\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abe0680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gets the index and synonym that is the highest scored synonym.\n",
    "def get_best_synonym(sentence):\n",
    "    \n",
    "    score_list = []\n",
    "    word_list = []\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        all_synonyms = get_all_synonyms(word)\n",
    "        \n",
    "        # Ignore current word if there are no synonyms.\n",
    "        if len(all_synonyms) == 0: \n",
    "            # append 0 score.\n",
    "            score_list.append(0)\n",
    "            word_list.append(\"none\")\n",
    "            continue\n",
    "        \n",
    "        wns = WordNetSimilarity()\n",
    "        similarity_scores = [wns.word_similarity(word, syn) for syn in all_synonyms]\n",
    "\n",
    "        # Uncomment the following to see process.\n",
    "        #print(word)\n",
    "        #print(all_synonyms)\n",
    "        \n",
    "        max_score = max(similarity_scores)\n",
    "        best_synonym_for_current_idx = all_synonyms[similarity_scores.index(max_score)]\n",
    "        \n",
    "        word_list.append(best_synonym_for_current_idx)\n",
    "        score_list.append(max_score)\n",
    "        \n",
    "    best_score_overall = max(score_list)\n",
    "    \n",
    "    if best_score_overall == 0:\n",
    "        print(\"No available synonyms\")\n",
    "        return None\n",
    "    \n",
    "    best_word_idx = score_list.index(best_score_overall)\n",
    "    best_word = word_list[best_word_idx]\n",
    "    \n",
    "    return best_word, best_word_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50bc68f",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea290b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a239d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_data_folder = 'AllDirectWatermarkedV2/'\n",
    "unmarked_data_folder = 'AllDirectUnmarkedV2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a26104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 1500\n",
      "No available synonyms\n",
      "1500 1600\n",
      "1600 1700\n",
      "1700 1800\n",
      "No available synonyms\n",
      "1800 1900\n",
      "No available synonyms\n"
     ]
    }
   ],
   "source": [
    "start_num_hundreds = 14\n",
    "num_hundreds = 5\n",
    "for i in range(start_num_hundreds + 1, num_hundreds + start_num_hundreds + 1):\n",
    "    start_range = (i - 1) * 100\n",
    "    end_range = (i) * 100\n",
    "    \n",
    "    print(start_range, end_range)\n",
    "    \n",
    "    current_sentences = sentences[start_range:end_range]\n",
    "\n",
    "    watermarked_sents = []\n",
    "    unmarked_sents = []\n",
    "    \n",
    "    for i in range(len(current_sentences)):\n",
    "        sentence = current_sentences[i].copy()\n",
    "        \n",
    "        if len(sentence) < 5:\n",
    "            continue\n",
    "        \n",
    "        result = watermark_sentence(sentence)\n",
    "        \n",
    "        if result is not None:\n",
    "            watermarked_sents.append(result)\n",
    "            unmarked_sents.append([word.lower() for word in current_sentences[i]])\n",
    "            \n",
    "    with open(unmarked_data_folder + 'unmarked' + str(start_range) + 'To' + str(end_range) + '.pkl', 'wb') as file:\n",
    "        pickle.dump(unmarked_sents, file)\n",
    "        \n",
    "    with open(marked_data_folder + 'watermarked' + str(start_range) + 'To' + str(end_range) + '.pkl', 'wb') as file:\n",
    "        pickle.dump(watermarked_sents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3cf294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Baltimore',\n",
       " 'and',\n",
       " 'Ohio',\n",
       " 'Railroad',\n",
       " 'announced',\n",
       " 'yesterday',\n",
       " 'it',\n",
       " 'would',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'total',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'its',\n",
       " 'payroll',\n",
       " 'by',\n",
       " '10',\n",
       " 'per',\n",
       " 'cent',\n",
       " 'through',\n",
       " 'salary',\n",
       " 'cuts',\n",
       " 'and',\n",
       " 'lay-offs',\n",
       " 'effective',\n",
       " 'at',\n",
       " '12:01',\n",
       " 'A.M.',\n",
       " 'next',\n",
       " 'Saturday',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c63ffd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'baltimore',\n",
       " 'and',\n",
       " 'oh',\n",
       " 'railroad',\n",
       " 'announced',\n",
       " 'yesterday',\n",
       " 'it',\n",
       " 'would',\n",
       " 'reduce',\n",
       " 'the',\n",
       " 'total',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'its',\n",
       " 'payroll',\n",
       " 'by',\n",
       " '10',\n",
       " 'per',\n",
       " 'cent',\n",
       " 'through',\n",
       " 'salary',\n",
       " 'cuts',\n",
       " 'and',\n",
       " 'lay-offs',\n",
       " 'effective',\n",
       " 'at',\n",
       " '12:01',\n",
       " 'a.m.',\n",
       " 'next',\n",
       " 'saturday',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "557b170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_watermarked = []\n",
    "full_unmarked = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebeb8e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(marked_data_folder)):\n",
    "    fpath = os.path.join(marked_data_folder, file)\n",
    "    \n",
    "    if os.path.isfile(fpath) and fpath.lower().endswith(\".pkl\"):\n",
    "        with open(fpath, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        \n",
    "        full_watermarked += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2653bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(unmarked_data_folder)):\n",
    "    fpath = os.path.join(unmarked_data_folder, file)\n",
    "    \n",
    "    if os.path.isfile(fpath) and fpath.lower().endswith(\".pkl\"):\n",
    "        with open(fpath, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        \n",
    "        full_unmarked += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37d0b696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_unmarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e62129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_watermarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e77c566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'thou',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_watermarked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ce74308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_unmarked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bc0419c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_dictionary = {\"watermarked\": [TreebankWordDetokenizer().tokenize(sentence).lower() for sentence in full_watermarked], \n",
    "#                    \"unmarked\": [TreebankWordDetokenizer().tokenize(sentence).lower() for sentence in full_unmarked]}\n",
    "full_dictionary = {\"watermarked\": full_watermarked, \n",
    "                   \"unmarked\": full_unmarked}\n",
    "full_df = pd.DataFrame.from_dict(full_dictionary)\n",
    "full_df.to_csv(\"DirectWatermarkedV3.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7f54813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'thou',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['watermarked'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c781fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'fulton',\n",
       " 'county',\n",
       " 'grand',\n",
       " 'jury',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['unmarked'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d697b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
